# Ch 6. 결정 트리

- **결정 트리**는 SVM 처럼 분류, 회귀, 다중출력도 가능한 머신러닝 알고리즘이며, 매우 복잡한 데이터셋도 학습할 수 있는 강력한 알고리즘임.

- 최근 자주 사용되는 가장 강력한 머신러닝 알고리즘 중 하나인 **랜덤 포레스트** 의 기본 구성 요소이기도 함.







## 6.1 결정 트리 학습과 시각화

- 사이킷 런의 **export_graphviz()** 함수를 사용해 그래프 정의를 .dot 파일로 출력하여 훈련된 결정 트리를 시각화 할 수 있음.







## 6.2 예측하기

- **루트 노드 root node** : 깊이가 0인 맨 꼭대기의 노드
- **자식 노드 child node**
- **리프 노드 leaf node** : 자식 노드를 가지지 않는 노드



- 결정 트리의 여러 장점 중 하나, 데이터 전처리가 거의 필요하지 않음.
  - 특성의 스케일을 맞추거나, 평균을 원점에 맞추는 작업이 필요없음.



- **불순도 Impurity** : 한 노드의 모든 샘플이 같은 클래스에 속해 있다면 이 노드를 순수(gini = 0)라고 함.



- 사이킷런은 이진 트리만 만드는 CRAT 알고리즘을 사용하기 때문에, 리프 노드 외의 모든 노드는 자식 노드를 2개 씩 가짐. 다른 알고리즘, ID3 같은 알고리즘을 쓴다면 둘 이상의 자식 노드를 가진 결정 트리를 만들 수 있음.



- **화이트박스 White box**모델 vs **블랙박스 Black box**모델
  - **화이트박스** 모델 : 결정 트리처럼 직관적이고 결정 방식을 이해하기 쉬움
  - **블랙박스** 모델 : 랜덤 포레스트나 신경망. 왜 그런 예측을 만드는지는 쉽게 설명하기 어려운 모델.







## 6.3 클래스 확률 추정

- 결정 트리는 한 샘플이 특정 클래스 k에 속할 확률을 추정할 수 있음.
- 샘플의 리프 노드를 찾기 위해 트리를 탐색하고, 그 노드에 있는 클래스 k의 훈련 샘플의 비율을 반환함.







## 6.4 CART 훈련 알고리즘

- 사이킷런은 결정 트리를 훈련시키기 위해 **CART, Classification and Regression Tree** 알고리즘을 사용함.
- 