# Ch 2.  머신러닝 프로젝트 처음부터 끝까지

- 프로젝트 단계 예제
  - 1. 큰 그림을 봅니다.
    2. 데이터를 구합니다.
    3. 데이터로부터 통찰을 얻기 위해 탐색하고 시각화합니다.
    4. 머신러닝 알고리즘을 위해 데이터를 준비합니다.
    5. 모델을 선택하고 훈련시킵니다.
    6. 모델을 상세하게 조정합니다.
    7. 솔루션을 제시합니다.
    8. 시스템을 론칭하고 모니터링하고 유지 보수합니다.





## 2.1 실제 데이터로 작업하기

- 인공적으로 만들어진 데이터셋보다 실제 데이터로 실험해보는 것이 좋음.
- 데이터 셋 예시
  - 유명한 공개 데이터 저장소
    - UC 얼바인Irvine 머신러닝 저장소
    - 캐글Kaggle 데이터셋
    - 아마존 AWS 데이터셋
  - 메타 포털
    - 데이터 포털
    - 오픈 데이터 모니터
    - 퀀들
  - 인기 있는 공개 데이터 저장소가 나열되어 있는 다른 페이지
    - 위키백고 머신러닝 데이터셋 목록
    - Quora.com
    - 데이터셋 서브레딧Reddit



- *책에서는 StatLib 저장소의 캘리포니아 주택 가격 데이터셋을 사용*





## 2.2 큰 그림 보기

- 캘리포니아 인구조사 데이터를 사용해 캘리포니아의 주택 가격 모델 만들기







### 2.2.1 문제 정의

- *'비즈니스의 목적이 정확히 무엇인가요?'*
- *'현재 솔루션은 어떻게 구성되어 있나요?'*
- 설계
  - 지도 학습 / 비지도 학습 / 강화 학습
  - 분류 / 회귀
  - 배치 학습 / 온라인 학습







### 2.2.2 성능 측정 지표 선택

- 일반적으로 회귀 문제에서는 **평균 제곱근 오차 Root Mean Square Error, RMSE** 가 선호됨
- 다른 경우, 예를 들면 이상치가 많은 경우, **평균 절대 오차 Mean Absolute Error, MAE (=평균 절대 편차 Mean Absolute Deviation)**



- **RMSE** 와 **MAE** 모두 예측값의 벡터와 타깃값의 벡터 사이의 ***거리***를 재는 방법.
  - ***거리*** 측정에 **노름 Norm**을 사용.
    - **RMSE** 는 L2 norm, 유클리디안 노름 Euclidean norm에 해당. 일반적인 거리 개념
    - **MAE** 는 L1 norm, 맨해튼 노름 Manhattan norm, Taxicab norm라고도 함.
    - 벡터 v의 Lk norm의 정의?
    - Norm의 지수가 클수록 큰 값의 원소에 치우치며 작은 값은 무시됨.
      - 때문에 RMSE가 MAE보다 이상치에 민감.
      - 하지만 이상치가 매우 드물면 RMSE가 잘 맞아 일반적으로 널리 사용됨.





### 2.2.3 가정 검사

- 지금까지 만든 가정을 나열하고 검사, 심각한 문제를 일찍 발견할 수도 있음.







## 2.3 데이터 가져오기

[코드 예제]<https://github.com/rickiepark/handson-ml2>







### 2.3.1 작업환경 만들기

- 주피터 노트북 설치





### 2.3.2 데이터 다운로드

- CSV 파일 받아서 추출





### 2.3.3 데이터 구조 훑어보기

- DataFrame
  - **head()** 메서드 사용해서 처음 다섯 행을 확인
  - **info()** 메서드는 데이터에 대한 간략한 설명과 특히 전체 행 수, 각 특성의 데이터 타입, null이 아닌 값의 개수를 확인하는데 유용
  - **value_counts()** 메서드로 어떤 카테고리가 있고, 각 카테고리마다 얼마나 많은 값이 있는지 확인
  - **describe()** 메서드는 숫자형 특성의 요약 정보를 보여줌
    - count, mean, min, max 등의 값과 백분위 중 1사분위수 25%, 2사분위수 50%, 3사분위수 75%에 해당하는 값을 보여줌





### 2.3.4 테스트 세트 만들기

- **데이터 스누핑 Data snooping** : 테스트 세트 전체를 살펴보다 특정 패턴을 인지하고 과대적합하는, 매우 낙관적인 추정으로 학습하게 됨.

- 테스트 세트는 무작위로 어떤 샘플을 선택해서 데이터셋 20% 정도를 뗴어 놓음

  - 만약 데이터셋이 매우 크다면 20%보다 낮게, 1%까지도 가능

  - 난수 생성



- 데이터셋이 충분히 크다면 일반적으로 괜찮지만, 샘플링 편향이 생길 수 있음.
  - 예를 들면 미국 인구의 51%가 여성이고 49%가 남성이라면 무작위로 뽑은 샘플에서도 비율이 유지되어야 함. 이를 **계층적 샘플링 Stratified sampling** 이라 함.
  - 전체 인구를 **계층 Strata**라고 하는 동질의 그룹으로 나누고, 테스트 세트가 전체 인구를 대표하도록 각 계층에서 샘플을 추출.







## 2.4 데이터 이해를 위한 탐색과 시각화

- 훈련 세트에 대해서만 탐색, 훈련 세트가 매우 크면 조작을 간단하고 빠르게 하기 위해 탐색을 위한 세트를 별도로 샘플링할 수도 있음.





### 2.4.1 지리적 데이터 시각화

- 이 경우, 위도와 경도같은 지리 정보가 있으니 모든 구역을 산점도로 만들어 데이터를 시각화하는 것이 좋음.







### 2.4.2 상관관계 조사

- **표준 상관계수 Standard correlation coefficient (피어슨 Pearson의 r 이라고도 부름)**
  - ***corr()*** 메서드를 이용해 쉽게 계산할 수 있음
  - 상관관계의 범위는 -1에서 1까지, 1에 가까우면 강한 양의 상관관계를 가진다는 뜻
    - 상관계수는 선형적인 상관관계만 측정, 기울기와 상관없음
  - pandas의 **scatter_matrix** 함수 사용





### 2.4.3 특성 조합으로 실험

- 여러 특성의 조합을 시도
  - 예를 들어 특정 구역의 방 개수는 가구 수를 모르는 경우 의미 없지만, 가구당 방 개수는 좋은 특성이 될 것.
  - 이런 특성을 만들어서 학습
- 이 단계보다는 처음 프로토타입을 잘 만드는게 나음. 하지만 반복적인 과정에서, 프로토타입을 만들고 실행한 후 그 결과를 분석해서 다시 이 단계로 돌아옴.





### 2.5 머신러닝 알고리즘을 위한 데이터 준비

- 수동으로 하는 대신 함수를 만들어 자동화 해야함
  - 어떤 데이터셋에 대해서도 데이터 변환은 손쉽게 반복 (예를 들어 새로운 데이터셋을 사용하는 경우)
  - 향후 프로젝트에서 사용할 수 있는 변환 라이브러리를 점진적으로 구축
  - 실제 시스템에서 알고리즘에 새 데이터를 주입하기 전에 변환에 사용가능
  - 여러 가지 데이터 변환을 쉽게 시도해보고, 어떤 조합이 가장 좋은지 확인하는데 편리



- **drop()**를 사용해 데이터 복사본을 만듦





### 2.5.1 데이터 정제

- 대부분의 머신러닝 알고리즘은 누락된 특성을 다루지 못하므로 이를 처리해 줘야함

  - **dropna()** : 해당 구역을 제거하거나,
  - **drop()** : 전체 특성을 삭제하거나,
  - **fillna()** : 어떤 값으로 채워줌. (0, 평균, 중간값 등)

  

- scikit-Learn의 **SimpleImputer** 사용.





### 2.5.2 텍스트와 범주형 특성 다루기

- scikit-Learn의 **OrdinalEncoder** 클래스 사용, 특정 카테고리를 텍스트에서 숫자로 변환.



- 머신러닝 알고리즘에서 가까이 있는 두 값이 떨어져 있는 두 값보다 더 비슷하다고 생각하는 문제가 있음.

  - 이를 해결하기 위해 **원-핫 인코딩 One-hot encoding**을 함

    - scikit-Learn에서는 **OneHotEncoder** 클래스를 제공

  - 카테고리의 값이 너무 많아 원-핫 인코딩이 너무 많은 수의 입력 특성을 만들고, 이는 훈련이 느려지고 성능을 감소시킬 수 있음.

    - 이런 경우 범주형 입력값을 이 특성과 관련된 숫자형 특성으로 바꾸거나,

    - **임베딩 Embedding**이라는 학습 가능한 저차원 벡터로 바꾸는 방법을 사용하거나 함. (**표현 학습 Representation learning**)

      



### 2.5.3 나만의 변환기

- 사이킷런이 제공하지 않는, 특별한 정제 작업이나 특성들을 조합하는 등의 작업을 위해 자신만의 변환기를 만들어야 할 때가 있음.
- 사이킷런의 기능과 연동하기 위해서는, 사이킷런은 상속이 아닌 덕 타이핑을 지원하므로, ***fit(), transform(), fit_transform()*** 메서드를 구현한 파이썬 클래스를 만들면 됨.







### 2.5.4 특성 스케일링

- 머신러닝 알고리즘은 입력 숫자 특성들의 스케일이 많이 다르면 잘 작동하지 않음 (트리 기반 알고리즘은 제외)



- 모든 특성의 범위를 같게 하기 위해
  - **min-max 스케일링**
  - **표준화 Standardization**



- **min-max 스케일링** 은 **정규화 Normalization**이라고도 불림.
  - 0~1 범위에 들도록 값을 이동하고 스케일을 조정.
    - 데이터에서 최솟값을 뺀 후, 최댓값과 최솟값의 차이로 나눠서 만듦.
      - 사이킷런에서는 ***MinMaxScaler*** 변환기를 제공, 0~1 사이를 원하지 않는다면  ***feature_range*** 매개 변수로 범위를 변경할 수 있음.



- **표준화** 는 다름.
  - 먼저 평균을 뺀 후 (그래서 표준화를 하면 항상 평균이 0이 됨), 표준편차로 나누어 결과 분포의 분산이 1이 되도록 함.
  - **min-max 스케일링** 과는 달리 표준화는 범위의 상한과 하한이 없어 어떤 알고리즘에서는 문제가 될 수 있음. (예를 들면 0~1의 입력값을 원하는 신경망)
  - 하지만 **표준화**는 이상치에 영향을 덜 받는 장점이 있음
    - 예를 들면 0~15의 값이 있는 데이터에 100이라는 이상치가 입력된 경우, min-max 스케일링은 다른 모든 값을 0~0.15로 만들어버리지만, 표준화는 크게 영향받지 않음.
  - 사이킷런에는 ***StandardScaler*** 변환기가 있음.



- 모든 변환기에서 스케일링은 테스트 세트가 포함된 전체 데이터가 아니고 훈련 데이터에 대해서만 ***fit()*** 메서드를 적용해야 함. 그런 다음 훈련 세트와 테스트 세트 (+ 새로운 데이터)에 대해  ***transform()*** 메서드를 사용.







### 2.5.5 변환 파이프라인

- 사이킷런에는 연속된 변환을 순서대로 처리할 수 있도록 도와주는  ***Pipeline*** 클래스가 있음.
- ***ColumnTransfomer***





## 2.6 모델 선택과 훈련

- 문제를 정의
- 데이터를 읽어 들이고, 탐색
- 훈련 세트 / 데이터 세트 나눔
- 변환 파이프라인으로 머신러닝 알고리즘에 주입할 데이터를 자동으로 정제하고 준비





### 2.6.1 훈련 세트에서 훈련하고 평가하기

- 예를 들면 선형 회귀 모델 훈련



- 오차가 없는 경우, 모델이 데이터에 너무 심하게 과대적합된 것으로 보임.
  - 훈련 세트의 일부분으로 훈련을 하고 다른 일부분은 모델 검증에 사용해야 함.





### 2.6.2 교차 검증을 사용한 평가

- 결정 트리 모델을 평가하는 방법을 생각해보자.
  - 우선 ***train_test_split*** 함수를 사용해 훈련 세트를 더 작은 훈련 세트와 검증 세트로 나누고,
  - 더 작은 훈련 세트에서 모델을 훈련시키고,
  - 검증 세트로 모델을 평가하는 방법이 있음.

-  다른 대안으로 사이킷런의 **k-겹 교차 검증 k-fold cross-validation** 기능을 사용할 수 있음.
  - 훈련 세트를 k개의 **폴드 fold**라 부르는 서브셋으로 무작위로 분할,
  - 결정 트리 모델을 k번 훈련하고 평가,
  - 매번 다른 **폴드**를 선택해 평가에 사용하고, 나머지는 훈련에 사용.
  - k개의 평가 점수가 담긴 배열이 결과가 됨.
    - 사이킷런의 교차 검즉은 *scoring* 매개변수에 (낮을수록 좋은) 비용 함수가 아닌, (클 수록 좋은) 효용 함수를 사용.
      - 그래서 평균 제곱 오차 MSE가 아닌 반대의 neg_mean_square_error 함수를 사용함.
  - 모델의 성능을 추정하는 것뿐만 아니라 이 추정이 얼마나 정확한지(표준편차)도 측정할 수 있음.
    - 하지만 모델을 여러 번 훈련해야 하므로, 비용이 비싸지는 단점이 있음.
- **RandomForestRegressor** 모델도 있음.
  - **RandomForest**는 특성을 무작위로 선택해서, 많은 결정 트리를 만들고, 그 예측을 평균 내는 방식으로 작동.
  - 이렇게 여러 다른 모델을 모아서 하나의 모델을 만드는 것을 **앙상블 학습** 이라고 하며, 머신러닝 알고리즘의 성능을 극대화하는 방법 중 하나임.



- 과대적합을 해결하는 방법은,
  - 모델을 간단히 하거나, 제한을 하거나 (규제),
  - 더 많은 훈련 데이터를 모음.



- 여러 종류의 머신러닝 알고리즘으로 하이퍼파라미터 조정에 너무 많은 시간을 들이지 않으면서, 다양한 모델 ( 다양한 커널의 서포트 벡터 머신, 신경망 등) 을 시도해 봐야 함.
  - 가능성 있는 2~5개 정도의 모델을 선정하는 것이 목표.







## 2.7 모델 세부 튜닝

- 가능성 있는 모델을 추린 후, 이 모델들을 세부 튜닝하는 방법들







### 2.7.1 그리드 탐색

- 가장 단순한 방법, 만족할 만한 하이퍼파라미터 조합을 찾을 때까지 수동으로 조정.
- 매우 지루하고, 많은 경우의 수를 탐색하기에는 시간이 부족할 것.



- 사이킷런의 ***GridSearchCV***를 사용하는 것을 추천.







### 2.7.2 랜덤 탐색

- 그리드 탐색 방법은 비교적 적은 수의 조합을 탐구할 때 좋음.
- 하지만 하이퍼파라미터 탐색 공간이 커지면 ***RandomizedSearchCV***를 사용하는 편이 더 좋음.
  - 각 반복마다 하이퍼파라미터에 임의의 수를 대입하여 지정한 횟수만큼 평가함.
    - 예를 들면 랜덤 탐색을 1000회 반복하도록 실행하면 하이퍼파라미터 마다 각기 다른 1000개의 값을 탐색함 (그리드 탐색에서는 하이퍼파라미터마다 몇 개의 값만 탐색)
    - 단순히 반복 횟수를 조절하는 것만으로, 탐색에 투입할 컴퓨팅 자원을 제어할 수 있음.







### 2.7.3 앙상블 방법

- 모델을 세밀하게 튜닝하는 또 다른 방버븐 최상의 모델을 연결해보는 것.
  - 예를 들면, 결정 트리의 앙상블인 랜덤 포레스트가 결정 트리 하나보다 성능이 더 좋은 것처럼.
  - 모델의 그룹 (또는 앙상블) 이 최상의 단일 모델보다 더 나은 성능을 발휘할 때가 많음.
    - 특히 개개의 모델이 각기 다른 형태의 오차를 만드는 경우가 그러함.





### 2.7.4 최상의 모델과 오차 분석

- 최상의 모델을 분석하면 문제에 대한 좋은 통찰을 얻기도 함.



- 오차가 생기는 이유를 이해하고 문제를 해결하는 방법을 찾아야 함.
  - 추가 특성을 포함시키거나,
  - 불필요한 특성을 제거하거나,
  - 이상치를 제외하는 등.







### 2.7.5 테스트 세트로 시스템 평가하기

- 모델을 어느정도 튜닝하고 만족할 만한 모델을 얻은 뒤, 테스트 세트에서 최종 모델을 평가하는 단계

- ***scipy.stats.t.interval()***를 사용해 일반화 오차의 95% **신뢰 구간 confidence interval**을 계산할 수 있음.

- 하이퍼파라미터 튜닝을 많이 했다면 교차 검증을 사용해 측정한 것보다 조금 성능이 낮은 것이 보통.
  - 테스트 세트에서 성능 수치를 좋게 하려고 하이퍼파라미터를 튜닝하면, 새로운 데이터에 일반화되기 어려우니 하지말 것.







## 2.8 론칭, 모니터링, 시스템 유지 보수

- 제품 시스템에 적용하기 위한 준비를 하는 단계 (예를 들면 코드를 정리하고 문서와 테스트 케이스를 작성하는 등)



- 모델을 상용 환경에 배포하기 위해
  - 전체 전처리 파이프라인과 예측 파이프라인이 포함된, 훈련된 사이킷런 모델을 (예를 들어 joblib을 사용하여) 저장
  - 또는 웹 어플리케이션이 REST API를 통해 질의할 수 있는 전용 웹 서비스로 모델을 감쌀 수 있음.
  - 인기 많은 또 다른 전략은 구글 클라우드 AI 플랫폼과 같은 클라우드에 배포하는 방법.



- 배포가 마지막이 아님.
  - 일정 간격으로 시스템의 실시간 성능을 체크하고, 성능이 떨어졌을 때 알람을 통지할 수 있는 모니터링 코드를 작성해야함.
  - 시간이 지나면서 모델이 낙후되는 경향이 있고, 이는 일반적인 현상임.
  - 실제로 세상은 변하고, 작년 데이터로 훈련된 모델은 올해 데이터에는 적용할 수 없을 것.
    - 카메라가 계속 바뀌기 때문에, 이미지 포맷, 선명도, 밝기, 해상도, 가로세로 비율 등이 변하면서 바뀌는 경우도 있음



- 모니터링 시스템을 준비하기 위해 자동화가 필요한 것.
  - 정기적으로 새로운 데이터를 수집하고 레이블을 닮
  - 모델을 훈련하고 하이퍼파라미터를 자동으로 튜닝하는 스크립트를 짦
  - 업데이트된 테스트 세트에서 새로운 모델과 이전 모델을 평가하는 스크립트 작성.



- 만든 모든 모델을 **백업 Backup** 해야 함.
  - 새로운 모델이 문제가 있는 경우, **롤백 Roll back**







## 2.9 직접 해보세요!

- 캐글 같은 경연 사이트가 시작하기 좋음







## 2.10 연습문제

1. 서포트 벡터 머신 회귀 (sklearn.svm.SVR) 를 kernel="linear" (하이퍼파라미터 C를 바꿔가며) 나 kernel="rbf" (하이퍼파라미터 C와 gamma를 바꿔가며) 등의 다양한 하이퍼파라미터 설정으로 시도해보세요. 지금은 이 하이퍼파라미터가 무엇을 의미하는지 너무 신경쓰지 마세요. 최상의 SVR 모델은 무엇인가요?



2. GridSearchCV를 RandomizedSearchCV로 바꿔보세요.



3. 가장 중요한 특성을 선택하는 변환기를 준비 파이프라인에 추가해보세요.



4. 전체 데이터 준비 과정과 최종 예측을 하나의 파이프라인으로 만들어보세요.



5. GridSearchCV를 사용해 준비 단계의 옵션을 자동으로 탐색해보세요.



[연습문제 정답] <https://github.com/rickiepark/handson-ml2>