# 1. 한눈에 보는 머신러닝

- 기존에 사용해온 오래된 머신러닝 기술들이 있다.
  - (예시) ***광학문자 판독기*** (Optical Character Recognition, OCR), ***스팸 필터*** (Spam filter)







## 1.1 머신러닝이란?

- (정의 1) 아서 사무엘 (Arthur Samuel)

  > [머신러닝은] 명시적인 프로그래밍 없이 컴퓨터가 학습하는 능력을 갖추게 하는 연구 분야다. 

- (정의 2) (공학적 정의) 톰 미첼 (Tom Mitchell)

  >어떤 작업 T에 대한 컴퓨터 프로그램의 성능을 P로 측정했을 때 경험 E로 인해 성능이 향상됐다면, 이 컴퓨터 프로그램은 작업 T와 성능측정 P에 대해 경험 E로 학습한 것이다.



- **훈련 세트(training set)** : 시스템이 학습하는데 사용하는 샘플
- **훈련 사례(training instance)** 혹은 **샘플** : 각 훈련 데이터
- **훈련 데이터(training data)** : 경험 E
- **정확도(accuracy)** : 정확히 분류된 메일의 비율 P







## 1.2 왜 머신러닝을 사용하는가?

1. 기존 솔루션으로는 많은 수동 조정과 규칙이 필요한 문제 : 머신러닝 모델을 사용하면 더 간단하고 잘 수행하게 할 수 있다.
2. 전통적인 방식으로는 전혀 해결 방법이 없는 복잡한 문제 : ML로 해결 방법을 찾을 수도 있다.
3. 유동적인 환경 : 새로운 데이터에 대해 계속 문제를 해결해야 하는 경우
4. 복잡한 문제와 대량의 데이터







## 1.3 머신러닝 시스템의 종류

1. 사람의 감독 하에 훈련하거나 아니거나

   > - 지도 학습
   > - 비지도 학습
   > - 준지도 학습
   > - 강화 학습

2. 실시간으로 점진적인 학습을 하는지 아닌지

   >- 온라인 학습
   >- 배치 학습

3. 단순하게 알고 있는 데이터 포인트와 새 데이터 포인트를 비교하는 것인지 아니면 훈련 데이터셋에서 패턴을 발견하여 예측 모델을 만드는지

   > - 사례 기반 학습
   > - 모델 기반 학습

- 이 범주들은 서로 배타적이지 않으며, 원하는 대로 연결 할 수도 있다. 
  - (예시) 심층 신경망 모델을 사용한 스팸 필터 : 온라인 + 모델 기반 + 지도 학습



### 1.3.1 지도 학습과 비지도 학습

---

### **1. 지도학습 (Supervised learning)**

- 전형적인 두 가지 지도학습
  - (예시) 레이블 (label), 분류 (classification)
- 또 다른 전형적인 작업
  - (예시) 예측 변수(predictor variable) : 주행거리, 연식, 브랜드 등의 특성(feature)을 사용해 중고차 가격이라는 타깃(target) 수치를 예측하는 것
    - 이런 종류의 작업을 회귀(regression)이라 함
- *속성 (attribute) 과 특성 (feature) 의 차이* : 속성은 데이터 타입을 말하고, 특성은 속성 + 값을 의미. 하지만 많은 사람들이 속성과 특성을 구분하지 않고 사용함



- ***<u>가장 중요한 지도 학습 알고리즘들</u>***

  > - k-최근접 이웃 (k-Nearest Neighbors)
  > - 선형 회귀 (Linear Regression)
  > - 로지스틱 회귀 (Logistic Regression)
  > - 서포트 벡터 머신 (Support Vector Machines, SVM)
  > - 결정 트리 (Decision Tree) 와 랜덤 포레스트 (Random Forests)
  > - 신경망 (Neural networks)



### **2. 비지도학습(Unsupervised learning)**

- 훈련 데이터에 레이블이 없는 경우
- 시스템이 아무런 도움 없이 학습해야만 한다



- ***<u>가장 중요한 비지도 학습 알고리즘들</u>***

  > - 군집 (Clustering)
  >
  >   - k-평균 (k-Means)
  >   - 계층 군집 분석 (Hierarchical Cluster Analysis, HCA)
  >     - (예시) 블로그 방문자를 그룹으로 묶음 : 방문자 중 문화책을 좋아하고, 저녁에 블로그 글을 읽고, 등등. 각 그룹을 나누고 다시 더 작은 그룹으로 세분화.
  >   - 기댓값 최대화 (Expectation Maximization)
  >
  > - 시각화 (Visualization) 와 차원 축소 (Dimensionality reduction)
  >
  >   - 시각화 (Visualization) : 레이블이 없는 대규모의 고차원 데이터를 넣으면 도식화가 가능한 2D나 3D 표현을 만들어 줌. 이를 통해 데이터가 어떻게 조직되어 있는지 이해, 패턴 발견 가능.
  >   - 차원 축소 (Dimensionality reduction) : 너무 많은 정보를 잃지 않으면서 데이터를 간소화. 상관관계가 있는 여러 특성 (feature)을 하나로 합침.
  >     - (예시) 특성 추출 (feature extraction) : 차의 주행거라와 연식을 차의 마모 정도를 나타내는 하나의 특성으로 합침.
  >     - *지도 학습 알고리즘 같은 머신러닝 알고리즘에 데이터를 주입하기 전에 차원을 줄이는 것이 유용할 때가 많음. 실행 속도, 디스크, 메모리 감소, 경우에 따라 성능이 좋아지기도 함*
  >
  >   - 주성분 분석 (Principal Component Analysis, PCA)
  >   - 커널 (Kernel) 주성분 분석 (PCA)
  >   - 지역적 선형 임베딩 (Locally-Linear Embedding, LLE)
  >   - t-SME (t-distributed Stochastic Neighbor Embedding)
  >
  > - 연관 규칙 학습 (Association rule learning)
  >
  >   - 어프라이어리 (Apriori)
  >   - 이클렛 (Eclat)



- **<u>그 외의 중요한 비지도 학습</u>**

  > - 이상치 탐지 (anomaly detection) 
  >   - (예시) 부정 거래를 막기 위해 이상한 신용카드 거래를 감지, 새로운 샘플이 정상 데이터인지 혹은 이상치인지 판단
  > - 연관 규칙 학습 (association rule learning) : 대량의 데이터에서 특성 간의 흥미로운 관계를 찾음
  >   - (예시) 바비큐 소스와 감자를 구매하는 사람은 스테이크를 구매하는 경향이 있다





### 3. 준지도 학습 (Semi-supervised learning) ###

- 레이블이 일부만 있는 데이터를 다루는 경우 (보통 레이블이 없는 데이터가 많고 레이블이 있는 데이터가 조금인 경우)
  - (예시) 구글 포토 호스팅 서비스, 가족사진을 올리면 얼굴 태그가 안된 사람들을 인식하고 레이블을 입력하게 함
- 대부분의 준지도 학습 알고리즘은 지도 학습 + 비지도 학습
  - (예시)
    - 심층 신뢰 신경망 (Deep Belief Network, DBN) : 제한된 볼츠만 머신 (Restricted Boltzmann Machine, RBM) 이라 불리는 비지도 학습에 기초한 후 지도 학습 방식으로 세밀하게 조정.





### 4. 강화 학습 (Reinforcement Learning)

- 강화 학습은 매우 다른 종류의 알고리즘
- 학습하는 시스템을 **에이전트**라고 하며, 환경(environment)을 관찰해서 행동(action)을 실행하고 그 결과로 **보상(reward)**또는 부정적인 보상인 **벌점(penalty)**을 받음. 시간이 지나면서 가장 큰 보상을 얻기 위해 **정책(policy)** 이라 부르는 최상의 전략을 스스로 학습.
- (예시 1) 보행로봇
- (예시 2) *알파고 AlphaGo*







## 1.3.2 배치 학습과 온라인 학습

- 입력 데이터의 스트림(stream)으로부터 점진적으로 학습할 수 있는지의 여부가 기준



### 1. 배치 학습 (batch learning)

- 시스템이 점진적으로 학습할 수 없는 경우.
- 가용한 데이터를 모두 사용해 훈련시켜야 함.
- 시간과 자원을 많이 소모하므로, 보통 오프라인에서 수행됨.
- **오프라인 학습(offline learning)** : 먼저 시스템을 훈련시키고, 그 다음 제품 시스템에 적용. 더 이상의 학습은 없음.



- 새로운 데이터를 학습하려면, 새로운 데이터 + 이전 테이터를 사용하여 시스템의 새로운 버전을 처음부터 다시 훈련시켜야 함.
- 대신 머신훈련 시스템의 훈련, 평가, 론칭하는 전체 과정을 자동화해서 사용할 수는 있음.
- 주식같은, 빠르게 변하는 데이터에 대해서는 가능한 사용하지 않는 편이 나음.
- 자원이 제한된 시스템에서 역시 가능한 사용하지 않는 편이 나음.





### 2. 온라인 학습

- **미니배치 (mini-batch)** 라 부르는 작은 묶음 단위로 데이터를 주입하여 시스템 훈련
- 주식같은, 빠른 변화에 스스로 적응해야하는 시스템에 적합
- 컴퓨팅 자원이 제한된 경우도 좋음
- 새로운 데이터 샘플을 학습하면 학습이 끝난 데이터는 버림, 이를 통해 많은 공간 절약 가능



- 사용하는 컴퓨터 보다 큰 데이터셋을 학습하는 경우도 사용가능.
  - **외부 메모리 (out-of-core) 학습** : 데이터 일부를 읽어 들이고 훈련하고 데이터를 버리고 다시 받는 과정을 반복
    - 단, 이 경우 보통 오프라인으로 실행하므로 온라인 학습보다는 *점진적 학습 (incremental learning)*이 더 나은 이름

- **학습률 (learning rate)** : 변화하는 데이터에 얼마나 빠르게 적응하는지에 대한 파라미터
  - 학습률을 높게 하면 시스템이 새 데이터에 빠르게 적응하지만, 예전 데이터를 금방 잊어버림.
  - 반대로 학습률이 낮으면 시스템이 더 느리게 학습, 대신 새로운 데이터에 있는 잡음이나 대표성 없는 데이터 포인트에 덜 민감해짐.



- 온라인 학습의 가장 큰 문제점은 시스템에 나쁜데이터가 주입되면, 시스템 성능이 점진적으로 감소한다는 점.
  - 입력 데이터를 모니터링(이상치 탐지 알고리즘)해서 비정상 데이터를 잡을 수 있음.





## 1.3.3 사례 기반 학습과 모델 기반 학습

- 어떻게 **일반화** 되는가에 따라 머신러닝 시스템을 분류

(미완)