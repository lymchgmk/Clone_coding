# Ch 3. 분류

- Ch 1 에서는 가장 일반적인 지도 학습인 회귀(값 예측)와 분류(클래스 예측)을, Ch 2 에서는 회귀 작업을 살펴보면서 선형 회귀, 결정 트리, 랜덤 포레스트를,
  - Ch 3 에서는 분류 시스템에 대해 집중적으로 다룰 것.







## 3.1 MNIST

- *MNIST* : 미국 고등학생들과 인구조사국 직원들이 손으로 쓴 70,000개의 작은 숫자 이미지 데이터 셋, 레이블 되어 있음.
  - 학습용으로 아주 많이 사용되며, 머신러닝 분야의 'Hello World'라 불림







## 3.2 이진 분류기 훈련

- 사이킷런의 ***SGDClassifier*** 클래스를 사용해 **확률적 경사 하강법 Stochastic Gradient Descent (SGD)** 분류기를 사용 가능.
  - **SGD**는 매우 큰 데이터셋을 효율적으로 처리하는 장점이 있음
    - 한 번에 하나씩 훈련 샘플을 독립적으로 처리하기 때문
    - 그래서 **SGD**는 온라인 학습에 잘 들어맞음







## 3.3 성능 측정

- 분류기 평가는 회귀 모델보다 훨씬 어려움, 사용할 수 있는 성능 지표가 많기 때문







### 3.3.1 교차 검증을 사용한 정확도 측정

- 2장에서 한 것 처럼 교차 검증은 모델을 평가하는 좋은 방법
  - 사이킷 런의 ***cross_val_score()*** 함수로 **k-겹 교차 검증**을 수행, ***SGDClassifier*** 모델을 평가.



- **정확도 accuracy** : 정확한 예측의 비율
  - 정확도는 분류기의 성능 측정 지표로 선호하지 않음.
    - **불균형한 데이터셋** (어떤 클래스가 다른 것보다 월등히 많은 경우) 을 다룰 때 특히 그러함.







### 3.3.2 오차 행렬

- 분류기의 성능을 평가하는 더 좋은 방법, **오차 행렬 Confusion matrix**
  - 클래스 A의 샘플이 클래스 B로 분류된 횟수를 세는 것.
    - 예를 들어, 분류기가 숫자 5의 이미지를 3으로 잘못 분류한 횟수를 오차 행렬의 5행 3열에 넣는 것.



- 실제 타깃과 비교할 수 있도록 예측값이 필요, ***cross_val_predict()*** 함수 사용.
  - ***cross_val_score()*** 함수처럼 **k-겹 교차 검증** 을 수행하지만, 평가 점수를 반환하지 않고 각 테스트 폴드에서 얻은 예측을 반환함.
    - 즉, 훈련 세트의 모든 샘플에 대해 깨끗한 (모델이 훈련하는 동안 보지 못했던 데이터에 대해 예측한) 예측을 얻음



- 오차행렬의 *행*은 **실제 클래스**, *열*은 **예측한 클래스**를 나타냄.
  - **음성 클래스**
  - **진짜 음성**
  - **거짓 양성**
  - **양성 클래스**
  - **거짓 음성**
  - **진짜 양성**



- 완벽한 분류기라면 진짜 양성과 진짜 음성만 가지고 있을 것이고 오차 행렬의 주대각선만 0이 아닌 값이 됨.



- **정밀도 Acurracy** 는 **재현율 Recall** 이라는 다른 지표와 같이 사용하는 것이 일반적.

  - **재현율 Recall**은 분류기가 정확하게 감지한 양성 샘플의 비율로, **민감도 Sensitivity** 또는 **진짜 양성 비율 True Positive Rate, TPR**이라고도 함.

    - **정밀도 Acurracy** =  ***TP*** / (***TP*** + ***FP***)

    - **재현율 Recall** = ***TP*** / (***TP*** + ***FN***)







### 3.3.3 정밀도와 재현율

- **F1 점수 F1 score** 라고 하는 하나의 숫자로 만들어 정밀도와 재현율을 표기

  - 특히, 두 분류기를 비교할 때 유용

  - **F1 점수** 는 정밀도와 재현율의 ***조화 평균 Harmonic mean***

    

- ***f1_score()*** 함수