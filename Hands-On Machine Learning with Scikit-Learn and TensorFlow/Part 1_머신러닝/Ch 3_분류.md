# Ch 3. 분류

- Ch 1 에서는 가장 일반적인 지도 학습인 회귀(값 예측)와 분류(클래스 예측)을, Ch 2 에서는 회귀 작업을 살펴보면서 선형 회귀, 결정 트리, 랜덤 포레스트를,
  - Ch 3 에서는 분류 시스템에 대해 집중적으로 다룰 것.







## 3.1 MNIST

- *MNIST* : 미국 고등학생들과 인구조사국 직원들이 손으로 쓴 70,000개의 작은 숫자 이미지 데이터 셋, 레이블 되어 있음.
  - 학습용으로 아주 많이 사용되며, 머신러닝 분야의 'Hello World'라 불림







## 3.2 이진 분류기 훈련

- 사이킷런의 ***SGDClassifier*** 클래스를 사용해 **확률적 경사 하강법 Stochastic Gradient Descent (SGD)** 분류기를 사용 가능.
  - **SGD**는 매우 큰 데이터셋을 효율적으로 처리하는 장점이 있음
    - 한 번에 하나씩 훈련 샘플을 독립적으로 처리하기 때문
    - 그래서 **SGD**는 온라인 학습에 잘 들어맞음







## 3.3 성능 측정

- 분류기 평가는 회귀 모델보다 훨씬 어려움, 사용할 수 있는 성능 지표가 많기 때문







### 3.3.1 교차 검증을 사용한 정확도 측정

- 2장에서 한 것 처럼 교차 검증은 모델을 평가하는 좋은 방법
  - 사이킷 런의 ***cross_val_score()*** 함수로 **k-겹 교차 검증**을 수행, ***SGDClassifier*** 모델을 평가.



- **정확도 accuracy** : 정확한 예측의 비율
  - 정확도는 분류기의 성능 측정 지표로 선호하지 않음.
    - **불균형한 데이터셋** (어떤 클래스가 다른 것보다 월등히 많은 경우) 을 다룰 때 특히 그러함.







### 3.3.2 오차 행렬

- 분류기의 성능을 평가하는 더 좋은 방법, **오차 행렬 Confusion matrix**
  - 클래스 A의 샘플이 클래스 B로 분류된 횟수를 세는 것.
    - 예를 들어, 분류기가 숫자 5의 이미지를 3으로 잘못 분류한 횟수를 오차 행렬의 5행 3열에 넣는 것.



- 실제 타깃과 비교할 수 있도록 예측값이 필요, ***cross_val_predict()*** 함수 사용.
  - ***cross_val_score()*** 함수처럼 **k-겹 교차 검증** 을 수행하지만, 평가 점수를 반환하지 않고 각 테스트 폴드에서 얻은 예측을 반환함.
    - 즉, 훈련 세트의 모든 샘플에 대해 깨끗한 (모델이 훈련하는 동안 보지 못했던 데이터에 대해 예측한) 예측을 얻음



- 오차행렬의 *행*은 **실제 클래스**, *열*은 **예측한 클래스**를 나타냄.
  - **음성 클래스**
  - **진짜 음성**
  - **거짓 양성**
  - **양성 클래스**
  - **거짓 음성**
  - **진짜 양성**



- 완벽한 분류기라면 진짜 양성과 진짜 음성만 가지고 있을 것이고 오차 행렬의 주대각선만 0이 아닌 값이 됨.



- **정밀도 Acurracy** 는 **재현율 Recall** 이라는 다른 지표와 같이 사용하는 것이 일반적.

  - **재현율 Recall**은 분류기가 정확하게 감지한 양성 샘플의 비율로, **민감도 Sensitivity** 또는 **진짜 양성 비율 True Positive Rate, TPR**이라고도 함.

    - **정밀도 Acurracy** =  ***TP*** / (***TP*** + ***FP***)

    - **재현율 Recall** = ***TP*** / (***TP*** + ***FN***)







### 3.3.3 정밀도와 재현율

- **F1 점수 F1 score** 라고 하는 하나의 숫자로 만들어 정밀도와 재현율을 표기

  - 특히, 두 분류기를 비교할 때 유용

  - **F1 점수** 는 정밀도와 재현율의 ***조화 평균 Harmonic mean***

    

- ***f1_score()*** 함수



- 정밀도와 재현율이 비슷할 수록 F1 점수가 높음
  - 상황에 따라 정밀도 vs 재현율 중요도가 다름
    - 예를 들면 어린아이에게 안정한 동영상을 걸러내는 분류기는 좋은 동영상이 많이 제외되더라도 (낮은 재현율), 안전한 동영상만 보여주는 (높은 정밀도) 분류기
- **정밀도/재현율 트레이드 오프** : 정밀도를 올리면 재현율이 줄고, 그 반대도 성립







### 3.3.4 정밀도/재현율 트레이드오프

- **결정 함수 Decision function**
  - 이 함수를 사용해서 각 샘플의 점수를 계산
    - 그 점수가 임곗값보다 크면 샘플을 양성 클래스에 / 낮으면 음성 클래스에 할당
  - 임곗값을 내리면 재현율이 높아지고 정밀도가 줄어듦
  - 반대로 임곗값을 올리면 재현율은 낮아지고 정밀도는 (보통) 높아짐
  - 재현율은 부드러운 곡선 / 정밀도는 거칠게 나올 수 있음



- 좋은 정밀도/재현율 트레이드오프를 선택하는 방법
  1. 사이킷런의 ***cross_val_predict()*** 함수로 훈련 세트의 모든 샘플에 대한 점수를 구하고, 결정 점수를 반환받도록 한 뒤, ***precision_recall_curve()***함수를 사용해서 모든 임계값에 대해 정밀도와 재현율을 계산.
     - 맷플롯립으로 임곗값의 함수로 정밀도와 재현율에 대한 그래프를 그림
  2. 재현율에 대한 정밀도 곡선을 그림.
     - 정밀도가 급격하게 줄어드는 지점 직전의 값을 선택
       - 물론 프로젝트의 목적아따라 다르게 지정.







### 3.3.5 ROC 곡선

- **수신기 조작 특성 Receiver Operation Characteristic, ROC** 곡선은 이진 분류에서 널리 사용.

  - **거짓 양성 비율 False Positive Rate, FPR** 에 대한 **진짜 양성 비율 True Positive Rate, TPR** 의 곡선
    - **FPR** 은 양성으로 잘못 분류된 음성 샘플의 비율이며,
      - **FPR** = 1 - ( **진짜 음성 비율 True Negative Rate, TNR** : 음성으로 정확하게 분류한 음성 샘플의 비율)
        - **TNR** 은 특이도 specificty 라고도 함.

  - 즉 **ROC** 곡선은 **민감도 (재현율)** 에 대한 **1-특이도** 그래프.



- 그래프를 그려보면 트레이드오프를 확인할 수 있음.
  - 재현율(TPR)이 높을수록 거짓 양성(FPR)이 증가.
  - 좋은 분류기는 재현율이 점선에서 최대한 멀리 떨어진, 왼쪽 위 모서리로 쏠린 모양의 그래프가 나와야 함.



- **곡선 아래의 면적 Area Under the Curve, AUC** 을 측정하여 분류기 비교.
  - 완벽한 분류기는 **ROC **의 **AUC** 가 1 / 완전한 랜덤 분류기는 0.5







## 3.4 다중 분류

- 이진 분류는 2개의 클래스를 구별 / **다중 분류기 Multiclass classifier (= Multinomial classifier)** 는 둘 이 상의 클래스를 구별
- 여러 개의 클래스를 직접 처리 : SGD 분류기, 랜덤 포레스트 분류기, 나이브 베이즈 분류기
- 이진 분류만 가능 : 로지스틱 회귀, 서포트 벡터 머신 분류기
  - 이진 분류기를 여러 개 사용해서 다중 클래스를 분류하는 기법도 있음.
    - **OVR, One-Versus-the-Rest (=OvA, one-versus-all)** 전략 : 각 분류기의 결정 점수 중에서 가장 높은 것을 클래스로 선택.
    - **OvO, One-Versus-One** 전략 : 클래스가 N개라면 N*(N-1)/2 개의 분류기가 필요한 전략.
      - 각 조합마다 이진 분류기를 훈련. 가장 많이 양성으로 분류된 클래스를 선택
      - 각 분류기의 훈련에 전체 훈련 세트 중 구별할 두 클래스에 해당하는 샘플만 필요한 장점이 있음.
    - 서포트 벡터 머신 같은 일부 알고리즘은 훈련 세트의 크기에 민감해서, 작은 훈련 세트에서 많은 분류기를 훈련시키는게 더 빨라서, **OvO**를 선호.
      - 하지만, 대부분의 이진 분류 알고리즘은 **OvR**을 선호.







## 3.5 에러 분석

- 실제 프로젝트라 가정하면 마주하는 단계



- 만들어진 에러의 종류를 분석
  - 먼저, **오차 행렬**
    - 주대각선의 값이 충분히 높아야 이미지가 올바르게 분류되었음을 나타냄.







## 3.6 다중 레이블 분류

- 분류기가 샘플마다 여러 개의 클래스를 출력해야 하는 경우.
  - 예를 들면, 얼굴 인식 분류기
- **다중 레이블 분류 Multilabel classification** 시스템 : 여러 개의 이진 꼬리표를 출력하는 분류 시스템



- 다중 레이블 분류기를 평가하는 방법
  - 프로젝트에 따라 적절한 지표는 다름
    - 예를 들면, 각 레이블의 F1 점수를 구하고 평균 점수를 계산
      - 레이블에 클래스의 **지지도 Support**를 가중치로 줄 수 있음







## 3.7 다중 출력 분류

- **다중 출력 다중 클래스 분류 Multioutput-multiclass classfication ( 다중 출력 분류 Multioutput classification)**
  - 다중 레이블 분류에서 한 레이블이 다중 클래스가 될 수 있도록 일반화한 것.(값을 두 개 이상 가질 수 있음.)







## 3.8 연습문제

생략, 코드 짜면서 풀어 볼 것.

