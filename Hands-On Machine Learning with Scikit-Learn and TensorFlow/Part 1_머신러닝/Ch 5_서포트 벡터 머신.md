# Ch 5. 서포트 벡터 머신

- **서포트 벡터 머신 Support vector machine, SVM** : 선형, 비선형 분류 / 회귀 / 이상치 탐색 에도 사용할 수 있는 다목적 머신러닝 모델
  - 머신러닝에서 가장 인기 있는 모델 중 하나이며, 필수
  - 특히 복잡한 분류 문제에 잘 맞고, 작거나 중간 크기의 데이터셋에 적합







## 5.1 선형 SVM 분류

- 두 개의 클래스를 나누고 있을 뿐만 아니라 가장 가까운 훈련 샘플로 부터 가능한 멀리 떨어져 있는 결정 경계를 가짐. 클래스 사이의 가장 폭이 넓은 도로와 같음. 그래서 **라지 마진 분류 Large Margin Classification** 이라고도 함.

- **서포트 벡터 Support vector** : 도로 경계를 결정하는 벡터. 도로 경계에 가장 가깝고, 두 데이터 셋을 대표한다고 할 수 있음.







### 5.1.1 소프트 마진 분류

- 모든 샘플이 도로 바깥쪽에 올바르게 분류되어 있는 경우를 **하드 마진 분류 Hard Margin Classification**이라 함.
  - 하드 마진 분류에는 2 가지 문제점이 있음
    - (1) 데이터가 선형적으로 구분될 수 있어야 제대로 작동하며,
    - (2) 이상치에 민감함

- 이런 문제를 피하기 위해 좀 더 유연한 모델 (이상치가 있어도 괜찮은)이 필요함.

  - 충분히 넓은 도로의 폭을 유지하는 것.

  - **마진 오류 Margin violation** : 샘플이 도로 중간이나 심지어 반대쪽에 있는 경우.
  - 위의 2가지 조건 사이의 적절한 균형을 잡아야함.
    - 이를 **소프트 마진 분류 Soft Margin Classification** 이라 함.







## 5.2 비선형 SVM 분류

- 선형적으로 분류할 수 없는 테이터셋이 실제로는 대부분임.
  - 비선형 데이터셋을 다루는 한 방법은 다항 특성과 같은 특성을 더 추가하는 것.
    - 특성을 추가해서 선형적으로 구분되는 데이터셋으로 만들어버리면 됨.







### 5.2.1 다항식 커널

- 다항식 특성을 추가하는 것은 간단하고 모든 머신러닝 알고리즘에서 잘 작동함.
- 하지만 낮은 차수의 다항식은 매우 복잡한 데이터셋을 표현 못하고 / 높은 차수의 다항식은 모델을 느리게 만듦.
- SVM에서는 이를 해결하기 위해 **커널 트릭 Kernel trick**이라는 수학적 기교를 사용함. 매우 좋음.
  - 실제로는 특성을 추가하지 않으면서 다항식 특성을 많이 추가한 것과 같은 결과를 얻을 수 있는 기교.







## 5.2.2 유사도 특성

- 비선형 특성을 다루는 또 다른 기법
  - 각 샘플이 특정 **랜드마크 Landmark** 와 얼마나 닮았는지 측정하는 **유사도 함수 Similarity function**으로 계산한 특성을 추가하는 방법.

