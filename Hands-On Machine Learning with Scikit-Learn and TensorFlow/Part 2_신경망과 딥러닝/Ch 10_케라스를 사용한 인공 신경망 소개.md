# Ch 10. 케라스를 사용한 인공 신경망 소개

- 지능적인 기계를 만들기 위해 뇌 구조를 모방
  - **인공 신경망 Artificial Neural Network (ANN)**
    - 딥러닝의 핵심, 다재다능하고 강력하고 확장성이 좋음.
      - 이미지 분류
      - 음성 인식 서비스의 성능 높이기
      - 비디오 추천
      - 딥마인드의 알파고
    - 아주 복잡한 대규모 머신러닝 문제를 다루는데 적합함.



- **다중 퍼셉트론 Multi-layer perceptron (MLP)**







## 10.1 생물학적 뉴런에서 인공 뉴런까지

- 인공 신경망은 1943년 신경생리학자 위런 매컬러 Warren McCulloch와 수학자 월터 피츠 Walter Pitts의 논문에서 처음 소개됨
- 침체기와 부흥, 다시 침체기와 부흥을 맞이함.
  - 신경망 훈련에 사용할 데이터가 많아짐
    - 인공 신경망은 규모가 크고 복잡한 문제에서 다른 머신러닝 기법보다 좋은 성능을 냄
  - 컴퓨터 하드웨어가 크게 발전, 무어의 법칙 Moore's Law 덕분
    - 게임 산업 덕분에 수백만 개의 강력한 GPU가 생산,
    - 클라우드 플랫폼의 환경이 제공됨
  - 훈련 알고리즘이 향상됨
    - 작은 변경이지만 커다란 영향을 끼침
  - 이론상의 제한이 실전에서 문제가 되지 않음이 밝혀짐
    - 지역 최적점에 갇혀서 해결책을 찾을 수 없을 것이라 생각했지만, 실제로는 이런일이 매우 드묾 (지역 최적점에 도달하더라도 일반적으로 전역 최적점에 매우 가까움)
      - 고차원 공간에서는 대부분 안장점같으며, 지역 최적점은 매우 드물고, 만약 있다면 전역 최적점에 가까운 값임이 밝혀짐
  - 투자와 진보의 선순환에 들어감







### 10.1.1 생물학적 뉴런

- **생물학적 신경망 Biological Neural Network (BNN)**







### 10.1.2 뉴런을 사용한 논리 연산

- 생물학적 뉴런에서 착안한 매우 단순한 신경망 모델, 인공뉴런
  - 하나 이상의 이진(on/off) 입력과 이진 출력 하나를 가짐
  - 단순히 입력이 일정 개수만큼 활성화되었을 때, 출력을 내보냄
  - 이런 간단한 모델로 네트워크를 만들면, 어떤 논리 명제도 계산할 수 있다는 것이 증명됨.
    - 논리곱, 논리합, 논리부정 등







### 10.1.3 퍼셉트론

- **퍼셉트론 Perceptron** : 가장 간단한 인공 신경망 구조 중 하나, 1957년 프랑크 로젠블라트 Frank Rosenblatt 가 제안.
  - **TLU (Threshold Logic Unit)** 또는 **LTU (Linear Threshold Unit)** 라고 불리는 인공 뉴런을 기반으로 함.
    - 입력과 출력이 이진이 아닌 어떤 숫자이고, 각각의 입력 연결은 가중치과 연관되어 있음
    - 입력의 가중치 합을 계산한 뒤, 계산된 합에 **계단 함수 Step function**을 적용하여 결과를 출력.
  - 일반적으로, **헤비사이드 계단 함수 Heaviside step function**을 가장 널리 사용함
    - 가끔 **부호 함수 sign function**을 대신 사용하기도 함
  - 간단한 선형 이진 분류 문제에 사용할 수 있음.
    - 입력의 선형 조합을 계산, 임곗값을 넘으면 양성 클래스를 출력, 임곗값을 넘지 않으면 음성 클래스를 출력.
      - 예를 들면, 꽃잎의 길이와 너비를 기반으로 붓꽃의 품종을 분류
    - 이 경우 **TLU**를 훈련한다는 것은 최적의 w0, w1, w2, ... 를 찾는다는 뜻
  - **퍼셉트론**은 층이 하나뿐인 **TPU**로 구성됨
    - 각 **TLU**는 모든 입력에 연결 됨
    - **완전 연결 층 Fully connected layer)** 또는 밀집층 **Dense layer** : 한 층에 있는 모든 뉴련이 이전 층의 모든 뉴런과 연결되어 있을 때
  - 보통 입력층은 입력 뉴런으로 구성되고, 편향 뉴런이 추가됨



- **헤브의 규칙 Hebb's rule** : 퍼셉트론이 훈련되는 방식. 뉴런이 동시에 활성화될 때마다 이들 사이의 연결 가중치가 증가. 오차가 감소되도록 연결을 강화시킴



- **퍼셉트론 수렴 이론 Perceptron convergence theorem** : 로젠블라트가 증명. 훈련 샘플이 선형적으로 구분될 수 있다면 이 알고리즘이 정답에 수렴함.



- 퍼셉트론을 여러 개 쌓아올리면 일부 제약을 줄일 수 있음, 이런 인공 신경망을 **다층 퍼셉트로 MLP** 라고 함.
  - **다층 퍼셉트론**은 XOR 문제를 풀 수 있음







### 10.1.4 다층 퍼셉트론과 역전파

- 다층 퍼센트론은 입력층 하나와 **은닉층 hidden layer** 이라 불리는 하나 이상의 TLU층과 마지막 출력층으로 구성 됨.
- 입력층과 가까운 층을 하위 층, 출력에 가까운 층을 상위 층
- 출력층을 제외한 모든 층은 편향 뉴련을 포함하고, 다음 층과 완전히 연결됨.



- 은닉층을 여러 개 쌓아 올린 인공 신경망을 **심층 신경망 Deep Neural Network (DNN)**

  - 1990년대에는 은닉층이 2개 이상인 경우를 DNN이라 봄, 그러나 현대에는 은닉층이 수십에서 수백 개인 신경망이 흔해서 기준이 애매함.

  - **딥러닝**은 심층 신경망을 연구하는 분야이며, 일반적으로는 연산이 연속하여 길게 연결된 모델 연구를 의미.
    - 그러나 많은 사람들은 얕더라도 신경망이 사용되면 딥러닝이라고 함



- 다층 퍼셉트론을 훈련하기 위해 오랫동안 성공못하다, 1986년 데이비드 루멜하트, 제프리 힌턴, 로날드 윌리엄스가 **역전파 Backpropagation** 훈련 알고리즘을 소개함.
  - **역전파** 알고리즘은 효율적인 기법으로 gradient를 자동으로 계산하는 경사 하강법임.
  - 네트워크를 두 번 (정방향 + 역방향) 통과하는 것만으로 모든 모델 파라미터에 대한 네트워크 오차의 gradient를 계산할 수 있음.
    - = 오차를 감소시키기 위해 각 연결 가중치와 편향값이 어떻게 바뀌어야 할지 알 수 있음.
    - gradient를 구한 뒤, 평범한 경사 하강법을 수행
    - 네트워크가 어떤 해결책으로 수렴될 때까지 반복
      - 자동으로 gradient를 계산하는 것을 **자동 미분 automatic differnentiation, audodiff** 라고 부름
        - 여러 자동 미분 기법 중, 역전파에서는 **후진 모드 자동 미분 reverse-mode autodiff** 를 사용.
          - 이 기법은 빠르고 정확, 미분할 함수가 변수가 많고 출력이 적은 경우 잘 맞음.



- 정리하면,
  - (1) 각 훈련 샘플에 대해 역전파 알고리즘이 먼저 예측을 만들고 (정방향 계산)
  - (2) 역방향으로 각 층을 거치면서 각 연결이 오차에 기여한 정도를 측정하고 (역방향 계산)
  - (3) 마지막으로 이 오차가 감소하도록 가중치를 조정함. (경사 하강법 단계)



- 이 알고리즘을 계선하기 위해, 계단 함수를 로지스틱(시그모이드) 함수로 변경함.
  - 계단 함수는 수평선 밖에 없으니 계산할 그레이디언트가 없지만,
  - 로지스틱 함수는 어디서든지 0이 아닌 그레이디언트가 잘 정의되어 있기 때문.
    - 확설화 함수는 보통 다음의 두가지를 사용함.
      - (1) ***하이퍼볼릭 탄젠트 함수 (쌍곡 탄젠트 함수)***
        - 로지스틱 함수처럼 S자 모양이고 연속적이며 미분 가능
        - 하지만 -1에서 1사이의 값 (로지스틱은 0에서 1사이)
        - 훈련 초기에 각 층의 출력을 원점 근처로 모으는 경향이 있고, 이는 종종 빠르게 수렴되도록 도와줌.
      - (2) ***ReLU 함수***
        - 연속적이지만, z=0에서 미분 가능하지 않음 (기울기가 갑자기 변해서 경사 하강법이 이상한 방향으로 튈 수 있음)
        - z < 0 일 때 도함수가 0이지만, 실제로 잘 작동하고 계산 속도가 빠른 장점이 있어서, 기본 활성화 함수로 사용 중.
        - 가장 중요한 점은, 출력에 최댓값이 없다는 점이 경사 하강법에 있는 일부 문제를 완화해줌. (Ch 11 참고)



- 활성화 함수가 필요한 이유?
  - 선형 변환은 여러 개 연결해도 선형 변환 뿐이기 때문.
    - 따라서, 층 사이에 비선형성을 추가하지 않으면, 아무리 층을 많이 쌓아도 하나의 층이나 마찬가지 결과가 나옴.
      - 이러면 복잡한 문제를 풀 수 없음
    - 반대로 비선형 활성화 함수가 있는 충분히 큰 심층 신경망은 이론적으로 어떤 연속 함수도 근사 가능.







### 10.1.5 회귀를 위한 다층 퍼셉트론

- 다층 퍼셉트론은 회귀 작업에 사용할 수 있음.
  - 값 하나를 예측하는데 출력 뉴런이 하나만 필요, 이 출력 뉴런이 예측된 값이면 됨.
  - 반면 *다변량 회귀 Multivariate regression* 에서는 동시에 (여러 값을 예측하는 경우) 출력 차원마다 출력 뉴련이 하나씩 필요함.
    - 예를 들면 이미지에서 물체의 중심 위치를 파악하는 경우, 2D좌표를 예측하려면 x와 y 좌표 2개의 값이 출력되어야 함.



- 일반적으로 회귀용 다층 퍼셉트론을 만들 때는 출력 뉴런에 활서오하 함수를 사용하지 않고 어떤 범위의 값도 출력되도록 함.
  - 하지만 출력이 항상 양수여야 한다면 출력층에 ReLU 활성화 함수를 사용하거나 softmax 활성화 함수를 사용할 수 있음.
    - *softplus 활성화 함수* : ReLU 함수의 변종으로, 
      - z < 0 일때 0에 가까워지고
      - z >> 0 일 수록 z에 가까움
  - 어떤 범위 안의 값을 예측하고 싶다면 로지스틱 함수나 하이퍼볼릭 탄젠트 함수를 사용하고 레이블의 스케일을 적절한 범위로 조절.
    - 로지스틱 함수는 0에서 1 사이를 출력하고,
    - 하이퍼볼릭 탄젠트 함수는 -1에서 1 사이를 출력함.



- 손실 함수는 일반적인 경우는 MSE를, 훈련 세트에 이상치가 많다면 MAE를 사용함.
  - 또는 이 둘을 조합한 *후버 Huber* 손실을 사용할 수 있음
    - 후버 손실은 오차가 임곗값 (전형적으로 1) 보다 작을 때는 2차 함수, 임곗값보다 클 때는 선형 함수.
      - 선형 함수 부분은 MSE 보다 이상치에 덜 민감하고,
      - 2차 함수 부분은 MAE 보다 빠르고 정확하게 수렴함.







### 10.1.6 분류를 위한 다층 퍼셉트론

- 다층 퍼셉트론은 분류에도 사용.
- ***이진 분류 Binary Classification*** 문제에서는 로지스틱 활성화 함수를 가진 하나의 출력 뉴련만 있으면 됨
  - 0과 1 사이의 실수를 출력.
    - 이를 양성 클래스에 대한 예측 확률로,
    - 1- (양성 클래스 예측 확률) 을 음성 클래스에 대한 예측 확률로 사용하면 됨.



- 다층 퍼셉트론으로 ***다중 레이블 이진 분류 Multilabel Binary Classification*** 문제를 쉽게 처리 가능함.
  - 예를 들어, 이메일이 스팸인지 아닌지 예측하고, 동시에 긴급한 메일인지 아닌지 예측하는 경우.
    - 출력 뉴런 2개가 각각 스팸 확률과 긴급한 메일 확률을 출력하면 됨.
      - 출력된 확률의 합이 1이 될 필요는 없음.
      - 모델은 어떤 레이블 조합도 출력할 수 있음.
        - 긴급하지 않은 메일, 긴급한 메일, 긴급하지 않은 스팸 메일, 심지어 긴급한 스팸 메일도 가능.



- 3개 이상의 클래스 중 한 클래스에만 속할 수 있다면, 클래스마다 하나의 출력 뉴련이 필요한 경우임.
  - 이 경우, 출력층에 소프트맥스 활성화 함수를 사용해야 함.
    - 소프트맥스 함수는 모든 예측확률을 0과 1사이로 만들고, 모두 더했을 때 1이 되도록 함. (클래스가 배타적인 경우 필요함)
      - 이를 ***다중 분류 Multiclass Classification*** 라고 함.
  - 확률 분포를 예측해야 하므로, 손실 함수는 일반적으로 *크로스 엔트로피 손실 Cross-entropy loss (로그 손실 Log Loss 라고도 함)* 을 사용.



- 즉 분류 MLP는 이진 분류, 다중 레이블 분류, 다중 분류에 사용가능 함.







## 10.2 케라스로 다층 퍼셉트론 구현하기

- 케라스는 모든 종류의 신경망을 손쉽게 만들고, 훈련 / 평가 / 실행 할 수 있는 고수준 딥러닝 API임.
- 텐서플로에 번들로 포함된 tf.keras를 사용할 것.



- 텐서플로우 1.x 버전은 복잡했지만, 텐서플로우 2는 파이토치만큼 간결하게 정리 됨.

- 과거 파이토치는 이식성이 제한적이고 계산 그래프의 해석이 없는 단점이 있었지만 파이토치 1.0 버전에서 많이 보완함.







### 10.2.1 텐서플로 2 설치

- virtualenv, pip로 설치

- 생략







### 10.2.2 시퀀셜 API를 사용하여 이미지 분류기 만들기

- 이미지 *MNIST* 데이터를 사용.

#### 케라스를 사용하여 데이터셋 적재하기

#### 시퀀셜 API를 사용하여 모델 만들기

- *Sequential* 모델은 가장 간단한 케라스의 신경망 모델로, 순서대로 연결된 층을 일렬로 쌓아서 구성.

- 그 다음 첫 번째 틍을 만들고 모델에 추가.

  - *Flatten* 층은 입력 이미지를 1D 배열로 변환함.

    - 즉, 입력 데이터 X에 대해 *X.reshape(-1,1)* 를 계산함.
    - 어떤 모델 파라미터도 없고, 간단한 전처리를 수행할 뿐.
    - 첫 층이므로 *input_shape*를 지정해야 함.

    - *Flatten* 층 대신 *keras.layers.InputLayer* 층을 추가할 수도 있음.

- 그 다음 *Dense* 은닉층을 추가. 활성화 함수로 *ReLU* 함수를 사용.

  - *Dense* 층 마다 각자 가중치 행렬을 관리.
    - 이 행렬에는 층의 뉴런과 입력 사이의 모든 연결 가중치가 포함됨.
    - 또한 뉴런마다 가지는 편향도 벡터로 관리

- 그 다음 두 번째 *Dense* 은닉층을 추가하고, 마찬가지로 ReLU 활성화 함수 사용.

- 마지막으로 *Dense* 출력층을 추가.

  - 배타적인 클래스이므로 소프트맥스 활성화 함수를 사용.



- *Dense* 층은 연결 가중치를 무작위로 초기화하고, 편향은 0으로 초기화 함.
  - 다른 초기화 방법을 사용하고 싶다면 층을 만들 때 *kernel_initializer*와 *bias_initializer* 매개변수를 설정하면 됨.
    - ***커널 kernel*** : 연결 가중치 행렬의 또 다른 이름



- 가중치 행렬의 크기는 입력의 크기에 달려있고, 이 때문에 *Sequential* 모델의 첫 층을 추가할 때 *input_shape* 매개변수를 지정하는 것.
  - 하지만 입력 크기를 지정하지 않아도 모델을 빌드하기 전까지 입력 크기를 기다려줘서 괜찮음.
    - 모델 빌드는 실제 데이터를 주입할 때나, *build()* 메서드를 호출할 때 일어남.





#### 모델 컴파일

- 모델을 만들고 나서 *compile()* 메서드를 호출하여 사용할 손실 함수와 *옵티마이저 optimizer* 를 지정해야 함.
- 부가적으로 훈련과 평가 시에 계산할 지표를 지정할 수 있음.



- 예시에서는 레이블이 정수 하나로 이루어져 있고, 클래스가 배타적이므로 *"sparse_categorical_crossentropy"* 손실을 사용함.
  - 만약 샘플마다 클래스 별 타깃 확률을 가지고 있다면 *"categorical_crossentropy"* 손실을 사용해야 함.
    - 정리하면 훈련 데이터의 라벨이 원-핫 백터면  *"categorical_crossentropy"*
    - 훈련 데이터의 라벨이 정수면 *"sparse_categorical_crossentropy"*



- 만약 이진 분류를 수행한다면 출력층에 *"softmax"* 함수 대신 *"sigmoid"* 함수를 사용하고, *"binary_crossentropy"* 손실을 사용함.

- 옵티마이터에 *"sgd"* 를 설정해서 확률적 경사 하강법을 사용해, 모델을 훈련
  - 앞서 말한 역전파 알고리즘 (후진 모드 자동 미분과 경사 하강법) dmf tngod
    - 기본값으로 lr = 0.01 설정되어있음





#### 모델 훈련과 평가

- 모델 훈련은 간단하게 *fit()* 메서드를 사용
- 입력 특성(X_train) 과 타깃 클래스(y_train), 훈련할 에포크 횟수(지정하지 않으면 기본값 1은 수렴에 좋지 않음), 검증 세트는 선택 사항.
- 훈련 세트 성능이 검증 세트 성능보다 월등히 높다면 훈련 세트에 과대적합되었거나, 버그가 있을 수 있음. (예를 들면 훈련 세트와 검증 세트 간의 데이터가 올바르지 않다거나.)



- 훈련 세트에 클래스가 편중되어 있다면 *fit()* 메서드를 호출할 때, *class_weight* 매개변수를 지정하는 것이 좋음.
  - 적게 등장하는 클래스는 높은 가중치를, 많이 등장하는 클래스는 낮은 가중치를 부여함.
  - 샘플별로 가중치를 부여하고 싶다면 *sample_weight* 매개변수를 사용
    - 만약 *class_weight* 와 *sample_weight* 가 모두 지정되면 케라스는 두 값을 곱해서 사용.
- 예를 들어 어떤 샘플은 전문가에 의해 레이블이 지정되고, 다른 샘플은 클라우드소실 플랫폼을 통해 레이블이 할당되었다면 샘플별 가중치가 도움이 될 수 있음. 아마 전자에 높은 가중치를 부여할 것.



- *fit()* 메서드가 반환하는 *History* 객체에는 훈련 파라미터 (*history.params*)와 수행된 에포크 리스트(*history.epoch*) 가 포함됨.
  - 에포크가 끝날 때 마다 훈련 세트와 검증 세트에 대한 손실과 측정한 지표를 담은 딕셔너리인 *history.history*는 가장 중요한 속성.
    - *history.history* 에 *plot()* 메서드를 호출해서 학습 곡선 Learning Curve를 볼 수 있음.



- 훈련하는 동안 훈련 정확도와 검증 정확도가 꾸준히 상승하고, 훈련 손실과 검증 손실은 감소하는것이 베스트.
  - 또한 검증 곡선이 훈련 곡선과 가까워야 과대적합 안되었음을 알 수 있음.
  - 그리고 검증 손실은 에포크가 끝난 뒤에 계산되고, 훈련 손실은 에포크가 진행되는 동안 계산되기 때문에, 훈련 곡선은 에포크의 절반만큼 왼쪽으로 이동해야 함.
- 일반적으로 충분히 오래 훈련시키면 훈련 세트의 성능이 검증 세트보다 높음. 따라서 검증 손실이 계속 감소한다면 모델이 충분히 수렴하지 않은 것으로 판단할 수 있음.
  - 케라스에서는 *fit()* 메서드를 다시 호출하면 중지되었던 곳에서 이어 훈련할 수 있음.



- 모델 성능이 만족스럽지 않으면 하이퍼파라미터를 튜닝하고 재훈련해야 함.
  - 맨 처음은 학습률을 튜닝.
  - 그 다음은 다른 옵티마이저를 테스트.
  - 여전히 성능이 안좋으면 층 개수, 층에 있는 뉴런 개수, 은닉층의 활성화 함수 등의 하이퍼파라미터 튜닝이 필요함.
  - 배치 크기도 튜닝.
- 모델 검증 정확도가 만족스러우면 상용 환경으로 배포하기 전에 테스트 세트로 모델을 평가하여 일반화 오차를 추정해야 함.
  - *evaluate()* 메서드 사용.



- 테스트 세트에서 하이퍼파라미터 튜닝을 하게 되면, 일반화 오차를 매우 낙관저긍로 추청하므로 해서는 안됨.





#### 모델을 사용해 예측을 만들기

- 그 다음 모델의 *predict()* 메서드를 사용해 새로운 샘플에 대한 예측을 만들 수 있음.
- 가장 높은 확률을 가진 클래스에만 관심이 있다면 *predict_classes()* 메서드를 사용.







### 10.2.3 시퀀셜 API를 사용하여 회귀용 다층 퍼셉트론 만들기

- 회귀 신경망을 사용하기 위해, 데이터를 적재하고, 누락된 데이터가 없는지 확인하고, 데이터를 적재한 후 훈련 세트 / 검증 세트 / 테스트 세트 로 나누고 모든 특성의 스케일을 조정함.
- 회귀용 MLP는 분류와 매우 비슷하지만,
  - 차이점은 출력층이 활성화 함수가 없는 하나의 뉴런을 가진다는 것,
  - 손실 함수로 MSE를 사용한다는 것
- 데이터셋에 잡음이 많다면 과대적합을 막기 위해 뉴런 수가 적은 은닉층 하나만 사용.



- Sequential API 말고, 입력과 출력이 여러 개거나 더 복잡한 네트워크 토폴로지를 갖는 신경망을 위해서, 케라스는 ***함수형 Functional*** API 를 제공함.







### 10.2.4 함수형 API를 사용해 복잡한 모델 만들기

- 복잡한 신경망의 한 예는 *와이드 & 딥 (Wide & Deep)* 신경망.
  - 입력의 일부 혹은 전체가 출력층에 바로 연결되어 있는데,
    - 신경망이 (깊게 쌓은 층을 사용한) 복잡한 패턴과
    - (짧은 경로를 사용한) 간단한 규칙을 모두 학습할 수 있음.
  - 반면 MLP는 네트워크에 있는 층 전체에 모든 데이터를 총과 시킴.



- (1) Input 객체를 만들고 shape와 dtype을 정의해 줌. 여러 개의 입력을 가질 수 있음.
- (2) 뉴런들과 ReLU 활성화 함수를 가진 Dense 층을 만듦. 만들어지자마자 입력과 함께 함수처럼 호출 되는데, 이를 함수형 API라고 하는 이유. 층이 연결될 방법을 알려주었을뿐 아직 어떤 데이터도 처리하지 않음
- (3) 두 번째 은닉층을 만들고 함수처럼 호출. 첫 번째 층의 출력을 전달 함.
- (4) Concatenate 층을 만들고 또 함수처럼 호출, 두 번째 은닉층의 출력과 입력을 연결.
- (5) 하나의 뉴런과 활성화 함수가 없는 출력층을 만들고, Concatenate 층이 만든 결과를 사용해 호출.
- (6) 마지막으로 사용할 입력과 출력을 지정하여 케라스 Model을 만듦.



- 와이드 경로와 딥 경로로 전달하는 방법은?
  - 그냥 입력을 여러개 사용하면 됨. 와이드 경로로 보낼 입력, 딥 경로로 보낼 입력을 각각 사용.



- 여러 개의 출력이 필요한 경우?
  - 예를 들어 그림에 있는 주요 물체를 분류하고 위치를 알아야 하는 경우.
    - 회귀 작업(물체 중심의 좌표와 너비, 높이를 찾음)과 분류 작업을 같이 해야하는 경우가 해당.
  - 또는 동일한 데이터에서 독립적인 여러 작업을 수행하는 경우.
    - 물론 작업마다 새로운 신경망을 훈련할 수도 있지만, 작업마다 하나의 출력을 가진 단일 신경망을 훈련하는 것이 보통 더 나은 결과를 냄.
      - 예를 들어 얼굴 사진으로 ***다중 작업 분류 Multitask Classification***을 수행하는 경우,
        - 한 출력은 사람의 얼굴 표정을 분류하고, 다른 출력은 안경을 썼는지 구별.
  - 또 다른 예는 규제 기법으로 사용하는 경우. (즉 과대적합을 줄이고 일반화 성능을 높이도록 훈련에 제약을 거는 경우)
    - 예를 들어 신경망 구조 안에 보조 출력을 추가해, 하위 네트워크가 나머지 네트워크에 의존하지 않고 그 자체로 유용한 것을 학습하는지 확인할 수 있음.



- 각 출력은 자신만의 손실 함수가 필요하므로, 모델을 컴파일할 떄 손실의 리스트(혹은 딕셔너리)를 전달해야 함.

  - 그러지 않으면 모든 출력의 손실 함수가 동일하다고 케라스가 가정함.

  - 또한 보조 출력과 주 출력의 가중치를 부여하고 싶은 경우 모델을 컴파일할 때 손실 가중치를 지정해줘야 함.







### 10.2.5 서브클래싱 API로 동적 모델 만들기

- 시퀀셜 API / 함수형 API 는 모두 선언적 Declarative 임.
  - 사용할 층과 연결 방식을 먼저 정의하고,
  - 그 다음에야 모델에 데이터를 주입하여 훈련이나 추론을 시작하는 방식을 말함.
- 이런 선언적 모델의 장점은?
  - 모델을 저장하거나 복사, 공유가쉬움
  - 모델의 구조를 출력하거나 분석하기 좋음
  - 프레임워크가 크기를 짐작하고, 타입을 확인하여 (데이터 주입 전에) 에러를 일찍 발견 가능
  - 층으로 구성된 정적 그래프이므로 디버깅도 쉬움
- 대신 단점은?
  - 정적임. 즉, 반복문을 포함하고 다양한 크기와 조건문이 필요한, 동적인 구조에 알맞지 않음.
    - 이 경우, **서브클래싱 Subclassing** API 를 사용하는게 정답.



- 클래스 인스턴스를 만들어 사용.
  - Input 클래스의 객체를 만들 필요없이, *call()* 메서드의 *input* 매개변수를 사용함.
  - 그 외에도 *call()* 메서드 안에서, for문, if문, 텐서플로 저수준 연산을 사용할 수 있음.
    - 대신 모델 구조가 *call()* 메서드 안에 숨겨져 있으므로,
      - 모델을 저장하거나 복사할 수 없음.
      - *summary()* 메서드를 호출하면 층의 목록만 나열되고 층 간의 연결 정보는 얻을 수 없음.
      - 타입과 크기를 미리 확인할 수 없음.
- 따라서, 높은 유연성이 필요하지 않는다면, 시퀀셜 API와 함수형 API를사용하는 것이 나음.







### 10.2.6 모델 저장과 복원

- 케라스는 HDF5 포맷을 사용.
  - (모든 층의 하이퍼파라미터를 포함하여) 모델 구조와
  - 층의 모든 모델 파라미터(즉 연결 가중치와 편향)와
  - (하이퍼파라미터와 현재상태를 포함한) 옵티마이저도 저장함.
- *SavedModel* 포맷을 사용하여 tf.keras 모델을 저장할 수 있음.







### 10.2.7 콜백 사용하기

- 훈련 도중 일정 간격으로 체크포인트를 저장해야 한다면?
  - *fit()* 메서드에서 **콜백 Callback** 매개변수를 사용하면 됨.
    - 에포크의 시작이나 끝, 각 배치 처리 전후 호출 가능.
      - 기본적으로는 매 에포크의 끝에서 호출 됨.



- ***EarlyStopping*** 을 사용하면 일정 에포크 동안 검증 세트에 대한 점수가 향상되지 않으면 훈련을 멈춤.



- 그 외에 사용자 정의 콜백을 만들어 사용할 수도 있음.







### 10.2.8 텐서보드를 사용해 시각화 하기

- 텐서보드는 매우 좋은 인터렉티브 시각화 도구.
  - 훈련하는 동안 학습 곡선을 그리거나, 여러 실행 간의 학습 곡선을 비교하는 등.







## 10.3 신경망 하이퍼파라미터 튜닝하기

- 신경망은 유연한 장점이 있지만, 동시에 조정할 파라미터가 너무 많음.
  - 어떤 하이퍼파라미터 조합이 최적인지 어떻게 알 수 있을까?
    - 많은 하이퍼파라미터 조합을 시도해보고, 검증 세트(혹은 K-폴드 교차 검증) 에서 가장 좋은 점수를 내는지 확인.



- 하이퍼파라미터 값의 범위를 크게 하여 빠르게 첫번째 랜덤 탐색 후,

  - 첫 번째 탐색의 최상의 하이퍼파라미터 값을 중심으로 더 좁은 범위를 탐색,
    - 이를 반복.
    - 대신, 이 방법은 시간이 많이 소요되고, 최상의 방법은 아님.

- 더 효율적으로 하이퍼파라미터 공간을 탐색하는 방법은, 탐색 지역이 좋다고 판명될 때 더 탐색을 수행하는 방법.

  - ***Hyperopt***
    - 모든 종류의 복잡한 탐색 공간에 대해 최적화를 수행할 수 있는 잘 알려진 라이브러리
  - ***Hyperas, kopt, Talos***
    - 케라스 모델을 위한 하이퍼파라미터 최적화 라이브러리 (Hyperas, kopt는 Hyperopt 기반)
  - ***케라스 튜너 Keras Tuner***
    - 사용하기 쉬움.
    - 구글이 만들었고, 시각화와 분석을 포함한 클라우드 서비스로도 제공될 예정.
  - ***Scikit-Optimize(skopt)***
    - 범용 최적화 라이브러리. 베이즈 Bayesian 최적화를 수행
  - ***Spearmint***
    - 베이즈 최적화 라이브러리.
  - ***Hyperband***
    - 리샤 리의 최근 하이퍼밴드 논문을 기반으로 구축, 빠른 하이퍼파라미터 튜팅 라이브러리.

  - ***Sklearn-Deap***
    - 진화 알고리즘 Evolutionary algorithm 기반의 하이퍼파라미터 최적화 라이브러리.



- 하이퍼파라미터 튜닝은 여전히 활발히 연구되는 영역. 진화 알고리즘이 요즘 추세.
  - 경사 하강법을 대체하여 **심층 신경 진화 Deep neuroevolution** 가 개별 신경망을 훈련하고 있음.



- 이런 여러 발전된 도구들과 서비스가 있더라도, 프로토타입을 빠르게 만들고, 탐색 공간을 제한하기 위해서는 각 하이퍼파라미터에 대해 생각하는 것은 도움이 됨.







### 10.3.1 은닉층 개수

- 은닉층 하나로도 많은 문제에서 납들할 만한 결과를 얻을 수 있음.
  - 이론적으로는 은닉층 하나인 MLP로도, 뉴런의 수만 충분하면 아주 복잡한 함수도 모델링 가능. (이를 *시벤코 정리*  또는 *일반 근사 이론* 이라 함.)
    - 하지만 복잡한 문제에서는 심층 신경망이 **파라미터 효율성 Parameter efficiency** 가 훨씬 좋음.
      - 또한 심층 신경망이 적은 수의 뉴런을 사용해서 동일한 양의 훈련 데이터에서 더 높은 성능을 낼 수 있는 장점이 있음.

- 그 원리는, 아래쪽 은닉층은 저수준의 구조를 모델링하고, 중간 은닉층은 저수준의 구조를 연결하고, 가장 위쪽 은닉층은 중간 수준의 구조를 연결해 고수준의 구조를 만드는 식.
  - 즉 계층 구조.

- 계층 구조는 빠른 수렴뿐만 아니라, 새로운 데이터에 일반화되는 능력도 향상시켜 줌.
  -  예를 들면, **전이 학습 Transfet Learning**







### 10.3.2 은닉층의 뉴런 개수

- 일반적으로 은닉층은 각 층의 뉴런을 점점 줄이는, 깔때기같은 모양으로 각 층의 뉴런 갯수를 구성함.
  - 저수준의 많은 특성이, 고수준의 적은 특성으로 합쳐지기 때문.
- 하지만, 요즘은 대부분의 경우 모든 은닉층에 같은 크기를 사용함.
  - 이 편이 동일하거나 나은 성능을 보임.
  - 다만, 첫 번째 은닉층은 크게 하는 것이 도움이 됨.



- 실전에서는 필요한 것 보다 더 많은 층과 뉴런을 가진 모델을 선택하고, 그런 다음 과대적합되지 않도록 조기종료 / 규제 기법을 사용하는 것이 간단하고 효과적임.
  - 소위 말하는 *스트레치 팬츠 Stretch pants* 방식







### 10.3.3 학습률, 배치 크기 그리고 다른 하이퍼파라미터

- 은닉층과 뉴런 개수 외의 MLP에서의 하이퍼파라미터





#### 학습률

